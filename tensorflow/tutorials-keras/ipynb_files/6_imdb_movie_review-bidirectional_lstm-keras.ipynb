{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_4q4S_3HRkX"
   },
   "source": [
    "# IMDB Movie Review Dataset Trained & Evaluated with Bidirectional LSTM (Keras)\n",
    "* Draft: 2020-11-25 (Wed)\n",
    "\n",
    "## Description\n",
    "* Binary classification problem in the field of Natural Language Processing (NLP)\n",
    "* Train a 2-layer bidirectional LSTM on the IMDB movie review sentiment classification dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZypQmpJHgKL"
   },
   "source": [
    "## IMDB Movie Review Dataset\n",
    "### Summary\n",
    "* 25,000 movie reviews from [IMDB](https://www.imdb.com/)\n",
    "  * Reviews have been preprocessed\n",
    "  * each review is encoded as a list of word indexes (integers)\n",
    "  * words are indexed by overall frequency in the dataset\n",
    "    * e.g. \"3\" encodes the 3rd most frequent word in the data\n",
    "    * \"0\" encodes any unknown word as a convention.\n",
    "    * This allows for quick filtering operations such as:\n",
    "      * only consider the top 10,000 most common words,\n",
    "      * but eliminate the top 20 most common words\n",
    "* labeled by sentiment (positive/negative); 2 classes\n",
    "* 50,000 training data; 10,000 test data\n",
    "\n",
    "### The Dataset\n",
    "[Large Movie Review Dataset](https://ai.stanford.edu/~amaas/data/sentiment/), [Andrew Maas](https://ai.stanford.edu/~amaas/), Stanford University\n",
    "* Publications using the dataset\n",
    "    * [Learning Word Vectors for Sentiment Analysis](https://ai.stanford.edu/~amaas/papers/wvSent_acl2011.pdf), Maas et.al, 2011.\n",
    "\n",
    "### Dataset with Keras API\n",
    "Keras API reference > Built-in small datasets > [IMDB movie review sentiment classification dataset](https://keras.io/api/datasets/imdb/)\n",
    "\n",
    "```python\n",
    "tf.keras.datasets.imdb.get_word_index(path=\"imdb_word_index.json\")\n",
    "```\n",
    "returns the word index dictionary. Keys are word strings, values are their index.\n",
    "* path: where to cache the data (relative to ~/.keras/dataset).\n",
    "\n",
    "```python\n",
    "tf.keras.datasets.imdb.load_data(\n",
    "    path=\"imdb.npz\",\n",
    "    num_words=None,\n",
    "    skip_top=0,\n",
    "    maxlen=None,\n",
    "    seed=113,\n",
    "    start_char=1,\n",
    "    oov_char=2,\n",
    "    index_from=3,\n",
    "    **kwargs\n",
    ")\n",
    "```\n",
    "loads the IMDB dataset.\n",
    "* start_char: int. The start of a sequence will be marked with this character. Defaults to 1 because 0 is used as \\[unk\\] or unknown.usually the padding character.\n",
    "* oov_char: int. The out-of-vocabulary character. Words that were cut out because of the num_words or skip_top limits will be replaced with this character.\n",
    "\n",
    "For details, see [IMDB movie review sentiment classification dataset](https://keras.io/api/datasets/imdb/).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d359ulKrHmYS"
   },
   "source": [
    "## Tutorials\n",
    "### Official tutorial by Keras\n",
    "[Code examples](https://keras.io/examples) / [Natural language processing](https://keras.io/examples/nlp) / [Bidirectional LSTM on IMDB](https://keras.io/examples/nlp/bidirectional_lstm_imdb/)\n",
    "``` text\n",
    "Author: fchollet\n",
    "Date created: 2020/05/03\n",
    "Last modified: 2020/05/03\n",
    "Description: Train a 2-layer bidirectional LSTM on the IMDB movie review sentiment classification dataset.\n",
    "```\n",
    "\n",
    "### Unofficial tutorials\n",
    " Google search: keras imdb example\n",
    "  * [IMDB - Sentiment analysis Keras and TensorFlow](https://www.kaggle.com/drscarlat/imdb-sentiment-analysis-keras-and-tensorflow), Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSMxifBIHq8p"
   },
   "source": [
    "## Sample Source Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7999,
     "status": "ok",
     "timestamp": 1606278126183,
     "user": {
      "displayName": "Tae-Hyung Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHVPEGKeIfrDrHTOwxwL6QYScms0ZPakVT2tBlL6k=s64",
      "userId": "11130252197837695405"
     },
     "user_tz": -540
    },
    "id": "tENCEK1dHqgy",
    "outputId": "925f7cd1-79bc-4499-ef7e-6df2ec706ed2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "25000 training sequences\n",
      "25000 validation sequences\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "max_features = 20000  # Only consider the top 20k words\n",
    "\n",
    "(x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data(\n",
    "    num_words=max_features\n",
    ")\n",
    "print( len(x_train), \"training sequences\" )\n",
    "print( len(x_val), \"validation sequences\" )\n",
    "\n",
    "maxlen = 200          # Only consider the first 200 words of each movie review\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7984,
     "status": "ok",
     "timestamp": 1606278126184,
     "user": {
      "displayName": "Tae-Hyung Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHVPEGKeIfrDrHTOwxwL6QYScms0ZPakVT2tBlL6k=s64",
      "userId": "11130252197837695405"
     },
     "user_tz": -540
    },
    "id": "bI_JWY0BRUZh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14430,
     "status": "ok",
     "timestamp": 1606278132639,
     "user": {
      "displayName": "Tae-Hyung Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHVPEGKeIfrDrHTOwxwL6QYScms0ZPakVT2tBlL6k=s64",
      "userId": "11130252197837695405"
     },
     "user_tz": -540
    },
    "id": "m0MJ_ehDRR50",
    "outputId": "3752c27f-e180-4370-f82a-383dc45b966a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 128)         2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 128)         98816     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,757,761\n",
      "Trainable params: 2,757,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Input for variable-length sequences of integers\n",
    "inputs = keras.Input( shape=(None,), dtype=\"int32\" )\n",
    "\n",
    "# Embed each integer in a 128-dimensional vector\n",
    "x = layers.Embedding( max_features, 128 )(inputs)\n",
    "\n",
    "# Add 2 bidirectional LSTMs\n",
    "x = layers.Bidirectional( layers.LSTM(64, return_sequences=True) )(x)\n",
    "x = layers.Bidirectional( layers.LSTM(64) )(x)\n",
    "\n",
    "# Add a classifier\n",
    "outputs = layers.Dense( 1, activation=\"sigmoid\" )(x)\n",
    "model = keras.Model( inputs, outputs )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 282629,
     "status": "ok",
     "timestamp": 1606278400852,
     "user": {
      "displayName": "Tae-Hyung Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHVPEGKeIfrDrHTOwxwL6QYScms0ZPakVT2tBlL6k=s64",
      "userId": "11130252197837695405"
     },
     "user_tz": -540
    },
    "id": "m-Ks3VwzSIA-",
    "outputId": "71565c7b-06f0-4374-d792-68d40dc08240"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 54s 68ms/step - loss: 0.3890 - accuracy: 0.8253 - val_loss: 0.4494 - val_accuracy: 0.7988\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 52s 66ms/step - loss: 0.2062 - accuracy: 0.9234 - val_loss: 0.3839 - val_accuracy: 0.8417\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 51s 65ms/step - loss: 0.1497 - accuracy: 0.9463 - val_loss: 0.3765 - val_accuracy: 0.8556\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 51s 65ms/step - loss: 0.0925 - accuracy: 0.9699 - val_loss: 0.4747 - val_accuracy: 0.8516\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 50s 64ms/step - loss: 0.1242 - accuracy: 0.9530 - val_loss: 0.5129 - val_accuracy: 0.8275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa38b5ef630>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile( \"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"] )\n",
    "model.fit( x_train, y_train, batch_size=32, epochs=5, validation_data=(x_val, y_val) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 282623,
     "status": "ok",
     "timestamp": 1606278400854,
     "user": {
      "displayName": "Tae-Hyung Kim",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhHVPEGKeIfrDrHTOwxwL6QYScms0ZPakVT2tBlL6k=s64",
      "userId": "11130252197837695405"
     },
     "user_tz": -540
    },
    "id": "QE7YcuMDSTBf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPUUDYMme6Ik8mLTWsxENuo",
   "collapsed_sections": [],
   "name": "6_imdb_movie_review-bidirectional_lstm-keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
