Number of devices: 2
batch_size_per_replica: 512
batch_size: 1024 = 512 * 2
8982 training samples
2246 test samples
11228 total samples
8982 training labels, 2246 test labels
? period ended december 31 shr profit 11 cts vs loss 24 cts net profit 224 271 vs loss 511 349 revs 7 258 688 vs 7 200 349 reuter 3
x_train (8982, 10000)
x_test  (2246, 10000)
y_train_dummy (8982, 46)
y_test_dummy  (2246, 46)
3 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
4 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
y_train (8982, 46)
y_test  (2246, 46)
3 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
4 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
x_val  (1000, 10000)
y_val  (1000, 46)
partial_x_train  (7982, 10000)
partial_y_train  (7982, 46)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 64)                640064    
_________________________________________________________________
dense_1 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_2 (Dense)              (None, 46)                2990      
=================================================================
Total params: 647,214
Trainable params: 647,214
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
1/8 [==>...........................] - ETA: 29s - loss: 3.8287 - accuracy: 0.01956/8 [=====================>........] - ETA: 0s - loss: 3.5686 - accuracy: 0.2375 8/8 [==============================] - 6s 272ms/step - loss: 3.4358 - accuracy: 0.2892 - val_loss: 2.3410 - val_accuracy: 0.6030
Epoch 2/10
1/8 [==>...........................] - ETA: 0s - loss: 2.2277 - accuracy: 0.64946/8 [=====================>........] - ETA: 0s - loss: 2.1197 - accuracy: 0.63488/8 [==============================] - 0s 28ms/step - loss: 2.0690 - accuracy: 0.6379 - val_loss: 1.6745 - val_accuracy: 0.6550
Epoch 3/10
1/8 [==>...........................] - ETA: 0s - loss: 1.5441 - accuracy: 0.71296/8 [=====================>........] - ETA: 0s - loss: 1.5040 - accuracy: 0.71358/8 [==============================] - 0s 32ms/step - loss: 1.4793 - accuracy: 0.7173 - val_loss: 1.3734 - val_accuracy: 0.7150
Epoch 4/10
1/8 [==>...........................] - ETA: 0s - loss: 1.2535 - accuracy: 0.75986/8 [=====================>........] - ETA: 0s - loss: 1.1904 - accuracy: 0.76538/8 [==============================] - 0s 28ms/step - loss: 1.1747 - accuracy: 0.7660 - val_loss: 1.2204 - val_accuracy: 0.7410
Epoch 5/10
1/8 [==>...........................] - ETA: 0s - loss: 0.9900 - accuracy: 0.80766/8 [=====================>........] - ETA: 0s - loss: 0.9710 - accuracy: 0.80458/8 [==============================] - 0s 28ms/step - loss: 0.9648 - accuracy: 0.8042 - val_loss: 1.1271 - val_accuracy: 0.7540
Epoch 6/10
1/8 [==>...........................] - ETA: 0s - loss: 0.8328 - accuracy: 0.83206/8 [=====================>........] - ETA: 0s - loss: 0.8153 - accuracy: 0.83588/8 [==============================] - 0s 27ms/step - loss: 0.8110 - accuracy: 0.8361 - val_loss: 1.0554 - val_accuracy: 0.7830
Epoch 7/10
1/8 [==>...........................] - ETA: 0s - loss: 0.6316 - accuracy: 0.87607/8 [=========================>....] - ETA: 0s - loss: 0.6742 - accuracy: 0.86578/8 [==============================] - 0s 28ms/step - loss: 0.6770 - accuracy: 0.8644 - val_loss: 1.0215 - val_accuracy: 0.7870
Epoch 8/10
1/8 [==>...........................] - ETA: 0s - loss: 0.6125 - accuracy: 0.87506/8 [=====================>........] - ETA: 0s - loss: 0.6035 - accuracy: 0.87488/8 [==============================] - 0s 28ms/step - loss: 0.6021 - accuracy: 0.8757 - val_loss: 0.9695 - val_accuracy: 0.7930
Epoch 9/10
1/8 [==>...........................] - ETA: 0s - loss: 0.5481 - accuracy: 0.88777/8 [=========================>....] - ETA: 0s - loss: 0.5178 - accuracy: 0.89368/8 [==============================] - 0s 27ms/step - loss: 0.5156 - accuracy: 0.8941 - val_loss: 0.9470 - val_accuracy: 0.8010
Epoch 10/10
1/8 [==>...........................] - ETA: 0s - loss: 0.4111 - accuracy: 0.92587/8 [=========================>....] - ETA: 0s - loss: 0.4354 - accuracy: 0.91798/8 [==============================] - 0s 26ms/step - loss: 0.4378 - accuracy: 0.9164 - val_loss: 0.9150 - val_accuracy: 0.8140
/home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])
/home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])
training_time: 0:00:08.972109
