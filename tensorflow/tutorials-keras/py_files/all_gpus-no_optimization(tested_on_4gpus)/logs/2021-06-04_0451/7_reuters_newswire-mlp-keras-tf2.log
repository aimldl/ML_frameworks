Number of devices: 4
8982 training samples
2246 test samples
11228 total samples
8982 training labels, 2246 test labels
? period ended december 31 shr profit 11 cts vs loss 24 cts net profit 224 271 vs loss 511 349 revs 7 258 688 vs 7 200 349 reuter 3
x_train (8982, 10000)
x_test  (2246, 10000)
y_train_dummy (8982, 46)
y_test_dummy  (2246, 46)
3 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
4 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
y_train (8982, 46)
y_test  (2246, 46)
3 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
4 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
x_val  (1000, 10000)
y_val  (1000, 46)
partial_x_train  (7982, 10000)
partial_y_train  (7982, 46)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 64)                640064    
_________________________________________________________________
dense_1 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_2 (Dense)              (None, 46)                2990      
=================================================================
Total params: 647,214
Trainable params: 647,214
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
 1/16 [>.............................] - ETA: 13s - loss: 3.8116 - accuracy: 0.0273 9/16 [===============>..............] - ETA: 0s - loss: 3.4276 - accuracy: 0.2520 16/16 [==============================] - 1s 37ms/step - loss: 3.1193 - accuracy: 0.3596 - val_loss: 1.7687 - val_accuracy: 0.6310
Epoch 2/10
 1/16 [>.............................] - ETA: 0s - loss: 1.6623 - accuracy: 0.6602 9/16 [===============>..............] - ETA: 0s - loss: 1.5929 - accuracy: 0.670016/16 [==============================] - 0s 9ms/step - loss: 1.5333 - accuracy: 0.6830 - val_loss: 1.3256 - val_accuracy: 0.6990
Epoch 3/10
 1/16 [>.............................] - ETA: 0s - loss: 1.1144 - accuracy: 0.7695 9/16 [===============>..............] - ETA: 0s - loss: 1.1086 - accuracy: 0.758116/16 [==============================] - 0s 9ms/step - loss: 1.1006 - accuracy: 0.7622 - val_loss: 1.1458 - val_accuracy: 0.7450
Epoch 4/10
 1/16 [>.............................] - ETA: 0s - loss: 0.8452 - accuracy: 0.8203 9/16 [===============>..............] - ETA: 0s - loss: 0.8638 - accuracy: 0.817316/16 [==============================] - 0s 9ms/step - loss: 0.8614 - accuracy: 0.8188 - val_loss: 1.0352 - val_accuracy: 0.7710
Epoch 5/10
 1/16 [>.............................] - ETA: 0s - loss: 0.7065 - accuracy: 0.8516 9/16 [===============>..............] - ETA: 0s - loss: 0.7016 - accuracy: 0.854816/16 [==============================] - 0s 9ms/step - loss: 0.6981 - accuracy: 0.8555 - val_loss: 0.9840 - val_accuracy: 0.7910
Epoch 6/10
 1/16 [>.............................] - ETA: 0s - loss: 0.5908 - accuracy: 0.8848 9/16 [===============>..............] - ETA: 0s - loss: 0.5849 - accuracy: 0.879216/16 [==============================] - 0s 9ms/step - loss: 0.5724 - accuracy: 0.8817 - val_loss: 0.9221 - val_accuracy: 0.8130
Epoch 7/10
 1/16 [>.............................] - ETA: 0s - loss: 0.4101 - accuracy: 0.9238 9/16 [===============>..............] - ETA: 0s - loss: 0.4679 - accuracy: 0.905316/16 [==============================] - 0s 9ms/step - loss: 0.4611 - accuracy: 0.9058 - val_loss: 0.8918 - val_accuracy: 0.8060
Epoch 8/10
 1/16 [>.............................] - ETA: 0s - loss: 0.4485 - accuracy: 0.9102 9/16 [===============>..............] - ETA: 0s - loss: 0.3723 - accuracy: 0.924616/16 [==============================] - 0s 9ms/step - loss: 0.3692 - accuracy: 0.9237 - val_loss: 0.9086 - val_accuracy: 0.8090
Epoch 9/10
 1/16 [>.............................] - ETA: 0s - loss: 0.3023 - accuracy: 0.939511/16 [===================>..........] - ETA: 0s - loss: 0.2976 - accuracy: 0.937816/16 [==============================] - 0s 8ms/step - loss: 0.2984 - accuracy: 0.9371 - val_loss: 0.8936 - val_accuracy: 0.8170
Epoch 10/10
 1/16 [>.............................] - ETA: 0s - loss: 0.2032 - accuracy: 0.964811/16 [===================>..........] - ETA: 0s - loss: 0.2387 - accuracy: 0.951116/16 [==============================] - 0s 8ms/step - loss: 0.2423 - accuracy: 0.9489 - val_loss: 0.9305 - val_accuracy: 0.7980
/home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])
/home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])
training_time: 0:00:03.251385
