Number of devices: 4
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz
   8192/2110848 [..............................] - ETA: 0s  40960/2110848 [..............................] - ETA: 2s 114688/2110848 [>.............................] - ETA: 1s 245760/2110848 [==>...........................] - ETA: 1s 581632/2110848 [=======>......................] - ETA: 0s1433600/2110848 [===================>..........] - ETA: 0s2113536/2110848 [==============================] - 0s 0us/step
8982 training samples
2246 test samples
11228 total samples
8982 training labels, 2246 test labels
Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json
  8192/550378 [..............................] - ETA: 0s 40960/550378 [=>............................] - ETA: 0s106496/550378 [====>.........................] - ETA: 0s212992/550378 [==========>...................] - ETA: 0s483328/550378 [=========================>....] - ETA: 0s557056/550378 [==============================] - 0s 0us/step
? period ended december 31 shr profit 11 cts vs loss 24 cts net profit 224 271 vs loss 511 349 revs 7 258 688 vs 7 200 349 reuter 3
x_train (8982, 10000)
x_test  (2246, 10000)
y_train_dummy (8982, 46)
y_test_dummy  (2246, 46)
3 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
4 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
y_train (8982, 46)
y_test  (2246, 46)
3 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
4 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
x_val  (1000, 10000)
y_val  (1000, 46)
partial_x_train  (7982, 10000)
partial_y_train  (7982, 46)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 64)                640064    
_________________________________________________________________
dense_1 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_2 (Dense)              (None, 46)                2990      
=================================================================
Total params: 647,214
Trainable params: 647,214
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
 1/16 [>.............................] - ETA: 14s - loss: 3.8296 - accuracy: 0.0488 9/16 [===============>..............] - ETA: 0s - loss: 3.4418 - accuracy: 0.3319 16/16 [==============================] - 2s 38ms/step - loss: 3.1238 - accuracy: 0.3969 - val_loss: 1.7441 - val_accuracy: 0.5990
Epoch 2/10
 1/16 [>.............................] - ETA: 0s - loss: 1.6142 - accuracy: 0.6641 9/16 [===============>..............] - ETA: 0s - loss: 1.6006 - accuracy: 0.653516/16 [==============================] - 0s 9ms/step - loss: 1.5389 - accuracy: 0.6687 - val_loss: 1.3104 - val_accuracy: 0.7090
Epoch 3/10
 1/16 [>.............................] - ETA: 0s - loss: 1.1375 - accuracy: 0.7559 9/16 [===============>..............] - ETA: 0s - loss: 1.1210 - accuracy: 0.761116/16 [==============================] - 0s 9ms/step - loss: 1.0980 - accuracy: 0.7656 - val_loss: 1.1420 - val_accuracy: 0.7500
Epoch 4/10
 1/16 [>.............................] - ETA: 0s - loss: 0.9019 - accuracy: 0.7910 9/16 [===============>..............] - ETA: 0s - loss: 0.8631 - accuracy: 0.811716/16 [==============================] - 0s 9ms/step - loss: 0.8478 - accuracy: 0.8178 - val_loss: 1.0487 - val_accuracy: 0.7730
Epoch 5/10
 1/16 [>.............................] - ETA: 0s - loss: 0.6761 - accuracy: 0.8555 9/16 [===============>..............] - ETA: 0s - loss: 0.6862 - accuracy: 0.858916/16 [==============================] - 0s 9ms/step - loss: 0.6759 - accuracy: 0.8597 - val_loss: 0.9775 - val_accuracy: 0.8010
Epoch 6/10
 1/16 [>.............................] - ETA: 0s - loss: 0.4886 - accuracy: 0.9062 9/16 [===============>..............] - ETA: 0s - loss: 0.5290 - accuracy: 0.891516/16 [==============================] - 0s 9ms/step - loss: 0.5289 - accuracy: 0.8914 - val_loss: 0.9302 - val_accuracy: 0.8040
Epoch 7/10
 1/16 [>.............................] - ETA: 0s - loss: 0.3581 - accuracy: 0.9277 9/16 [===============>..............] - ETA: 0s - loss: 0.4016 - accuracy: 0.920416/16 [==============================] - 0s 9ms/step - loss: 0.4098 - accuracy: 0.9184 - val_loss: 0.9450 - val_accuracy: 0.7950
Epoch 8/10
 1/16 [>.............................] - ETA: 0s - loss: 0.3695 - accuracy: 0.9238 9/16 [===============>..............] - ETA: 0s - loss: 0.3388 - accuracy: 0.934816/16 [==============================] - 0s 9ms/step - loss: 0.3390 - accuracy: 0.9338 - val_loss: 0.9053 - val_accuracy: 0.8110
Epoch 9/10
 1/16 [>.............................] - ETA: 0s - loss: 0.2948 - accuracy: 0.943410/16 [=================>............] - ETA: 0s - loss: 0.2717 - accuracy: 0.945016/16 [==============================] - 0s 8ms/step - loss: 0.2755 - accuracy: 0.9430 - val_loss: 0.9189 - val_accuracy: 0.8080
Epoch 10/10
 1/16 [>.............................] - ETA: 0s - loss: 0.2294 - accuracy: 0.960910/16 [=================>............] - ETA: 0s - loss: 0.2232 - accuracy: 0.952116/16 [==============================] - 0s 8ms/step - loss: 0.2273 - accuracy: 0.9500 - val_loss: 0.9133 - val_accuracy: 0.8160
/home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])
/home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])
training_time: 0:00:03.301882
