Number of devices: 5
batch_size_per_replica: 512
batch_size: 2560 = 512 * 5
8982 training samples
2246 test samples
11228 total samples
8982 training labels, 2246 test labels
? period ended december 31 shr profit 11 cts vs loss 24 cts net profit 224 271 vs loss 511 349 revs 7 258 688 vs 7 200 349 reuter 3
x_train (8982, 10000)
x_test  (2246, 10000)
y_train_dummy (8982, 46)
y_test_dummy  (2246, 46)
3 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
4 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
y_train (8982, 46)
y_test  (2246, 46)
3 [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
4 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
x_val  (1000, 10000)
y_val  (1000, 46)
partial_x_train  (7982, 10000)
partial_y_train  (7982, 46)
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense (Dense)                (None, 64)                640064    
_________________________________________________________________
dense_1 (Dense)              (None, 64)                4160      
_________________________________________________________________
dense_2 (Dense)              (None, 46)                2990      
=================================================================
Total params: 647,214
Trainable params: 647,214
Non-trainable params: 0
_________________________________________________________________
Epoch 1/10
1/4 [======>.......................] - ETA: 3s - loss: 3.8557 - accuracy: 0.00864/4 [==============================] - ETA: 0s - loss: 3.7468 - accuracy: 0.20124/4 [==============================] - 2s 185ms/step - loss: 3.7311 - accuracy: 0.2211 - val_loss: 3.0575 - val_accuracy: 0.5100
Epoch 2/10
1/4 [======>.......................] - ETA: 0s - loss: 3.0379 - accuracy: 0.50633/4 [=====================>........] - ETA: 0s - loss: 2.9114 - accuracy: 0.54474/4 [==============================] - 0s 37ms/step - loss: 2.8566 - accuracy: 0.5573 - val_loss: 2.2669 - val_accuracy: 0.6150
Epoch 3/10
1/4 [======>.......................] - ETA: 0s - loss: 2.1830 - accuracy: 0.65704/4 [==============================] - ETA: 0s - loss: 2.0935 - accuracy: 0.66234/4 [==============================] - 0s 36ms/step - loss: 2.0831 - accuracy: 0.6626 - val_loss: 1.8238 - val_accuracy: 0.6510
Epoch 4/10
1/4 [======>.......................] - ETA: 0s - loss: 1.7286 - accuracy: 0.68443/4 [=====================>........] - ETA: 0s - loss: 1.6820 - accuracy: 0.69234/4 [==============================] - 0s 37ms/step - loss: 1.6621 - accuracy: 0.6950 - val_loss: 1.5942 - val_accuracy: 0.6900
Epoch 5/10
1/4 [======>.......................] - ETA: 0s - loss: 1.4100 - accuracy: 0.72814/4 [==============================] - ETA: 0s - loss: 1.4040 - accuracy: 0.72614/4 [==============================] - 0s 37ms/step - loss: 1.4022 - accuracy: 0.7260 - val_loss: 1.4433 - val_accuracy: 0.7020
Epoch 6/10
1/4 [======>.......................] - ETA: 0s - loss: 1.2640 - accuracy: 0.75164/4 [==============================] - ETA: 0s - loss: 1.2434 - accuracy: 0.75194/4 [==============================] - 0s 36ms/step - loss: 1.2404 - accuracy: 0.7520 - val_loss: 1.3289 - val_accuracy: 0.7270
Epoch 7/10
1/4 [======>.......................] - ETA: 0s - loss: 1.1179 - accuracy: 0.78594/4 [==============================] - ETA: 0s - loss: 1.1043 - accuracy: 0.78144/4 [==============================] - 0s 37ms/step - loss: 1.1028 - accuracy: 0.7812 - val_loss: 1.2801 - val_accuracy: 0.7300
Epoch 8/10
1/4 [======>.......................] - ETA: 0s - loss: 1.0238 - accuracy: 0.78794/4 [==============================] - ETA: 0s - loss: 1.0175 - accuracy: 0.79144/4 [==============================] - 0s 42ms/step - loss: 1.0157 - accuracy: 0.7921 - val_loss: 1.2010 - val_accuracy: 0.7350
Epoch 9/10
1/4 [======>.......................] - ETA: 0s - loss: 0.9349 - accuracy: 0.80624/4 [==============================] - ETA: 0s - loss: 0.9145 - accuracy: 0.81064/4 [==============================] - 0s 37ms/step - loss: 0.9139 - accuracy: 0.8107 - val_loss: 1.1592 - val_accuracy: 0.7580
Epoch 10/10
1/4 [======>.......................] - ETA: 0s - loss: 0.8854 - accuracy: 0.81804/4 [==============================] - ETA: 0s - loss: 0.8511 - accuracy: 0.82484/4 [==============================] - 0s 40ms/step - loss: 0.8483 - accuracy: 0.8252 - val_loss: 1.1206 - val_accuracy: 0.7580
/home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])
/home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/gpu_cuda11.0/lib/python3.7/site-packages/tensorflow/python/keras/datasets/reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])
training_time: 0:00:03.590966
